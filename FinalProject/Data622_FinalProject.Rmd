---
title: "Data622 - Group2 - FinalProject"
author: "Amit Kapoor"
date: "11/26/2021"
output:
  html_document:
    fig_width: 15
    highlight: pygments
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    latex_engine: xelatex
    toc: yes
  always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align="center", fig.width = 10)
```


```{r libraries, include=FALSE, warning=FALSE, message=FALSE}
# Libraries
library(dplyr)
library(summarytools)
library(reshape2)
library(ggplot2)
library(DataExplorer)
library(caret)
library(tidyverse)
library(DataExplorer)
library(mice)
library(MASS)
library(e1071)
library(tree)
library(randomForest)
library(corrplot)
library(kableExtra)
library(htmltools)
library(fastDummies)
```


# Overview
The dataset for final project is from the UCI Machine Learning Repository. This dataset was donated by Ron Kohavi and Barry Becker. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)). Relevant paper is from Ron Kohavi, "Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996. Prediction task is to determine whether a person makes over 50K a year.


# Approach




# Data Exploration

There are 48842 observations of 15 variables. Each observation is for individual's income data with it's corresponding variables of interest. Below is the description of the variables of interest in the data set. 

|VARIABLE NAME|DESCRIPTION|
|--|----|
|age|continuous|
|workclass|Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked|
|fnlwgt|continuous|
|education|Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool|
|education-num|continuous|
|marital-status|Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse|
|occupation|Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces|
|relationship|Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried|
|race|White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black|
|sex|Female, Male|
|capital-gain|continuous|
|capital-loss|continuous|
|hours-per-week|continuous|
|native-country|United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands|
|income|>50K, <=50K|



```{r}
income_data <- read.csv("https://raw.githubusercontent.com/amit-kapoor/Data622Group2/main/FinalProject/data/census_income.csv", 
                        check.names = FALSE) %>% 
  na_if("")

# categorical columns as factors
income_data <- income_data %>% 
  mutate(workclass=as.factor(workclass),
         education=as.factor(education),
         marital_status=as.factor(marital_status),
         occupation=as.factor(occupation),
         relationship=as.factor(relationship),
         race=as.factor(race),
         sex=as.factor(sex),
         native_country=as.factor(native_country),
         income=as.factor(income))

```



```{r}
dfSummary(income_data, style = 'grid', graph.col = FALSE)
```


```{r}
summary(income_data)
```



```{r}
income_data %>% 
  count(income) %>% 
  ggplot(data=., aes(x=factor(income), y=n)) + 
  geom_col() + 
  xlab("Income") + 
  ylab("Frequency") + 
  ggtitle("Frequency of Income") + 
  theme_classic()
```



```{r, cat-bar, fig.length =30, fig.width=10}

# select categorical columns
cat_cols = c()
j <- 1
for (i in 1:ncol(income_data)) {
  if (class((income_data[,i])) == 'factor') {
      cat_cols[j]=names(income_data[i])
      j <- j+1
  }
}

income_fact <-  income_data[cat_cols]
# long format
income_factm <- melt(income_fact, measure.vars = cat_cols, variable.name = 'metric', value.name = 'value')

# plot categorical columns
ggplot(income_factm, aes(x = value)) + 
  geom_bar(aes(fill = metric)) + 
  facet_wrap( ~ metric, nrow = 5L, scales = 'free') + coord_flip() + 
  theme(legend.position = "none")
```


```{r plot_num}
plot_histogram(income_data, geom_histogram_args = list("fill" = "tomato4"))
```



```{r}
ggplot(income_data, aes(x=native_country, fill=income)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
ggplot(income_data, aes(x=workclass, fill=income)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
ggplot(income_data, aes(x=education, fill=income)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


```{r}
ggplot(income_data, aes(x=sex, fill=income)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```




```{r}
ggplot(income_data, aes(x=race, fill=income)) + 
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


```{r corr}
cors <- income_data %>% 
  select_if(is.numeric) %>% 
  na.omit() %>%
  cor()
corrplot::corrplot(cors, method="number")

```




# Data Preparation


## Handling missing values

```{r}
index <- income_data == "?"
is.na(income_data) <- index
```



```{r}
# finding NAs now in income_data
sum(!complete.cases(income_data))
```


```{r}
income_data_clean <- income_data[complete.cases(income_data),]
dim(income_data_clean)
```


```{r miss-plot}
# plot missing values
plot_missing(income_data_clean)
```



```{r}
library(tidyr)
df <- income_data_clean
df %>% 
  dplyr::select_if(is.integer) %>% 
  gather(key, value) %>% 
  ggplot(aes(key, value)) + geom_boxplot() # What is fnlwgt?
df %>% 
  dplyr::select_if(is.integer) %>% 
  gather(key, value) %>% 
  ggplot(aes(key, value)) + geom_boxplot(aes(fill = key)) + facet_wrap(~key, scales = "free") # Lots of outliers 
```


The `fnlwgt` variable (i.e. final weight) is being removed since it has no predictive power and it is a feature to allocate similar weights to people with similar demographic characteristics. We are also removing variable `education` since it is just a label of `education_num` column.

```{r}
# removing columns fnlwgt and education
income_data_clean <- income_data_clean %>% 
  dplyr::select(-c(fnlwgt, education))
```


## Preprocess using transformation

For highly-skewed feature distributions, we will perform boxcox transformation for these column to reduce the skewness and make it more Gaussian. Also combining the center and scale transforms will standardize the data. Now the features will have a mean value of 0 and a standard deviation of 1. This preprocessing uses the caret package's 'preprocessing' function to return a box cox transformation on all numeric variables in our income dataset. These numeric variables include age, education_num, capital_gain, capital_loss and hours_per_week.  


```{r}
set.seed(622)

# Center and scaling for numeric features
income_data_tf <- income_data_clean %>% 
  dplyr::select(c("age", "education_num" , "capital_gain", "capital_loss","hours_per_week")) %>%
  preProcess(method = c("BoxCox", "center","scale")) %>% 
  predict(income_data_clean)

head(income_data_tf)
```


```{r plot_num}
plot_histogram(income_data_tf, geom_histogram_args = list("fill" = "tomato4"))
```



```{r}
income_data_tf$income <- plyr::mapvalues(income_data_tf$income, from = c('>50K','<=50K'), to = c(1,0))
head(income_data_tf)
```




## Training and Test Partition

In this step for data preparation we will partition the training dataset in training and validation sets using `createDataPartition` method from `caret` package. We will reserve 70% for training and rest 30% for validation purpose.

```{r partition}
set.seed(622)
partition <- createDataPartition(income_data_tf$income, p=0.70, list = FALSE)

training <- income_data_tf[partition,]
testing <- income_data_tf[-partition,]

```

# Build Models

Decide on the models we should use and share the workload.

## Logistic Regression

First we're prepping the data to convert factors into dummy variables within the training and test sets.

```{r}
# https://www.marsja.se/create-dummy-variables-in-r/
library(fastDummies)
set.seed(622)
training.dum <- dummy_cols(training, 
                           select_columns = c("workclass",
                                              "marital_status",
                                              "occupation", 
                                              "relationship", 
                                              "race", 
                                              "sex", 
                                              "native_country"),
                           remove_selected_columns = TRUE)
```

```{r}
set.seed(622)
testing.dum <- dummy_cols(testing, 
                           select_columns = c("workclass",
                                              "marital_status",
                                              "occupation", 
                                              "relationship", 
                                              "race", 
                                              "sex", 
                                              "native_country"),
                           remove_selected_columns = TRUE)
```


```{r}
# https://stats.idre.ucla.edu/r/dae/logit-regression/
# https://www.datacamp.com/community/tutorials/logistic-regression-R

logit.income <- glm(income ~., data = training.dum, family = "binomial")
summary(logit.income)
```

```{r}
logit.probs <- predict(logit.income, type = "response")
logit.probs[1:5]
```

```{r}
logit.pred <- ifelse(logit.probs > 0.5, "Up", "Down")
```



## Decision Trees

In a decision tree model the data is split into distinct options of 'yes' or 'no' based on parameters that make the options possible. These splits are called nodes and the decisions made at them can be mapped. For example, we provide a small decision tree that shows how decisions can be made based on credit history, coapplicant income, and property area.

```{r}
# Check Number of Levels for each Factor
training %>% map(levels) %>% map(length)
```

```{r dt-model}
# Decision Trees model
#set.seed(622)
#tree.income = tree(income~., data=training)
#summary(tree.income)
#plot(tree.income)
#text(tree.income, pretty = 0)
```

We also review which variables are most important for making decisions in our model.These are shown in the plot as a straight line extending from the axis to the length of its importance to the model. Accuracy was also used to select the optimal model using the largest value where our final tree depth  used for this model is 1. 


```{r Decision}
# Decision Trees model
#set.seed(622)
#control <- trainControl(method="repeatedcv", number=10, repeats=3, search='grid')
#metric <- "Accuracy"
#tunegrid <- expand.grid(.maxdepth=c(1:15))
#tree.income <- train(income~., data = training, method="rpart2", tuneGrid=tunegrid, trControl=control)
#print(tree.income)
#plot(tree.income)

#treeImp <- varImp(tree.income, scale = FALSE)
#plot(treeImp, top = 10)
```

```{r dt-pred}
# prediction from decision tree model
#tree.predict <- predict(tree.income, testing,type='raw')
#mean(tree.predict == testing$income) # accuracy
#conf.mat.decisiontree <- confusionMatrix(tree.predict, testing$income)
#conf.mat.decisiontree
```

Our decision Tree model accuracy comes out as ~81%. As shown in the confusion matrix, there is room for improvement in this model's sensitivity among other variables. We try to improve this with the random forest model. 

## Random Forests

A random forest model works by building a number of decision trees and selecting the most accurate decisions from the trees. These decisions are randomized and in our case, tries 3 variables at each node or split in the tree. We set our number of trees to 500 and train the model to predict loan status. We review the variables of most importance in the model and in this case, give the model a boost to improve accuracy. 

```{r rf}
set.seed(622)
# Random Forest model
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
metric <- "Accuracy"
tunegrid <- expand.grid(.mtry=c(1:15))
rf.income <- train(income~., data = training, method="rf",tuneGrid=tunegrid, trControl=control)
print(rf.income)
plot(rf.income)

rfImp <- varImp(rf.income, scale = FALSE)
plot(rfImp, top = 10)
```

```{r rf-pred}
# prediction from random forest model
rf.predict <- predict(rf.loans, testing,type='raw')
mean(rf.predict == testing$Loan_Status) # accuracy
conf.mat.randomforest <- confusionMatrix(rf.predict, testing$income)
conf.mat.randomforest
```

Our random Forest model accuracy comes out as ~82%. This is an improvement upon our decision model and the sensitivity did increase as we desired. 



# Model Performance

Include a table of results

# Conclusion



# References

https://archive.ics.uci.edu/ml/datasets/Census+Income




# Code Appendix


```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}

```
















